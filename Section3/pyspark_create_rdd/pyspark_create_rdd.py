# -*- coding: utf-8 -*-
"""pyspark_create_rdd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14cStLw5ZmYPj65Cx9bi6p4yP-6YECUql
"""

!wget https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz
!tar -xvf spark-3.1.1-bin-hadoop2.7.tgz
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.1-bin-hadoop2.7"
!pip install findspark
import findspark
findspark.init()

from pyspark.sql import SparkSession
from pyspark import SparkContext

spark = SparkSession.builder.master("local[*]").getOrCreate()

sc = spark.sparkContext

my_rdd = sc.parallelize([20,40,50,60,70])

type(my_rdd)

my_rdd.collect()

!wget https://raw.githubusercontent.com/futurexskill/bidata/master/retailstore.csv

!ls

my_csv_rdd = sc.textFile('retailstore.csv')

my_csv_rdd.collect()

type(my_csv_rdd)

my_csv_rdd.first()

my_csv_rdd.take(3)

for line in my_csv_rdd.collect():
  print(line)
  print("hello")

